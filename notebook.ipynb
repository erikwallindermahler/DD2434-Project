{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project DD2434\n",
    "## Run instructions\n",
    "Tested in python 3.12.6, in a .venv environment\n",
    "\n",
    "## Datasets\n",
    "### Text document datasets\n",
    "The original paper used 4 datsets from different newsgroups, sci.crypt, sci.med, sci.space and soc.religion.christian, which are available at `URL`\n",
    "\n",
    "We also used `DATASET`\n",
    "\n",
    "### Image datasets\n",
    "\n",
    "\n",
    "The original paper used 13 monochromatic images of still life as the basis for the image datasets, which are unfortunately not available any longer. \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import scipy\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalizecolumns(d):\n",
    "    \"\"\"\n",
    "    Return a matrix where the columns have unit length\n",
    "    \"\"\"\n",
    "    \n",
    "    o = np.zeros(d.shape)\n",
    "    for col in range(d.shape[1]):\n",
    "        total_length = 0\n",
    "        for row in range(d.shape[0]):\n",
    "            total_length += d[(row,col)]**2\n",
    "        \n",
    "        for row in range(d.shape[0]):\n",
    "            if total_length == 0:\n",
    "                continue\n",
    "            o[(row,col)] = d[(row,col)]/np.sqrt(total_length)\n",
    "    return o\n",
    "    \n",
    "    \n",
    "\n",
    "def RP(dataset,k):\n",
    "    \"\"\"\n",
    "    Dataset - d x N, where d is the # of dimensions, N is the # of data points.\n",
    "    Creates appropriate matrix R (k x d), to transform into a lower dimension representation\n",
    "    \"\"\"\n",
    "    d = dataset.shape[0]\n",
    "    return normalizecolumns(np.random.normal(size=(k,d)))\n",
    "\n",
    "\n",
    "def SRP(dataset,k):\n",
    "    d = dataset.shape[0]\n",
    "    o = np.zeros((k,d))\n",
    "    for row in range(k):\n",
    "        for col in range(d):\n",
    "            r = np.random.random()\n",
    "            if r < 1/6:\n",
    "                o[(row,col)] = np.sqrt(3)\n",
    "            elif r > 5/6:\n",
    "                o[(row,col)] = -np.sqrt(3)\n",
    "    return normalizecolumns(o)\n",
    "\n",
    "def SVD(dataset,k):\n",
    "    \"\"\"\n",
    "    Returns d x k matrix, correponding to the k largest eigenvalues's eigenvectors.\n",
    "    Calculated through SVD - more efficient methods exist since most are ignored\n",
    "    \"\"\"\n",
    "    svd_res = np.linalg.svd(dataset)\n",
    "    U = svd_res.U\n",
    "    return U[:,:k].transpose()\n",
    "\n",
    "def DCT(dataset,k):\n",
    "    return(scipy.fftpack.dct(dataset.transpose(),n = k,type=2,norm='ortho').transpose())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(v):\n",
    "    norm = np.linalg.norm(v)\n",
    "    if norm == 0: \n",
    "       return v\n",
    "    return v / norm\n",
    "\n",
    "def similarity(v1,v2,v_type):\n",
    "    \"\"\"\n",
    "    Returns a measurement of similarity, depending on the v_type. \n",
    "    \"\"\"\n",
    "    nv1 = normalize(v1)\n",
    "    nv2 = normalize(v2)\n",
    "    \n",
    "    if v_type == \"text\":\n",
    "        return np.dot(nv1,nv2)\n",
    "    elif v_type == \"image\":\n",
    "        return np.linalg.norm(nv1 - nv2)\n",
    "    else:\n",
    "        raise ValueError(\"Invalid v_type, should be either 'text', or 'image'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ -2.61604051  -5.23208101  -7.84812152 -19.98687238]\n",
      " [ -0.3953885   -0.79077701  -1.18616551   0.7245222 ]]\n",
      "[[ 1.41421356  2.82842712  4.24264069  8.48528137]\n",
      " [ 0.          0.          0.         -2.82842712]]\n"
     ]
    }
   ],
   "source": [
    "a = np.matrix([[1,2,3,4],[1,2,3,8],[1,2,3,8],[1,2,3,8],[1,2,3,8],[1,2,3,8],[1,2,3,8]])\n",
    "\n",
    "print(SVD(a,2) * a)\n",
    "\n",
    "print(DCT(a,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Dataset: d x N\n",
    "\n",
    "def pipeline(dataset,method,v_type,numpairs,k_min,k_max,k_step):\n",
    "    \n",
    "    N = dataset.shape[1]\n",
    "    \n",
    "    # Select random pairs from the dataset\n",
    "    pairs = []\n",
    "    for i in range(numpairs):\n",
    "        r1 = np.random.randint(N)\n",
    "        r2 = np.random.randint(N)\n",
    "        \n",
    "        # Don't choose the same point twice\n",
    "        while r2 == r1:\n",
    "            r2 = np.random.randint(N)\n",
    "        pairs.append([dataset[:,r1],dataset[:,r2]])\n",
    "    \n",
    "    output = {}\n",
    "    \n",
    "    all_sim_diffs = []\n",
    "    runtimes      = []\n",
    "    ks            = []\n",
    "    \n",
    "    for k in range(k_min,k_max,k_step):\n",
    "        t0 = time.time()\n",
    "        # Tranformation matrix\n",
    "        R = method(dataset,k)\n",
    "        summed_sim_diff = 0\n",
    "        for pair in pairs:\n",
    "            x1 = pair[0]\n",
    "            x2 = pair[1]\n",
    "            \n",
    "            tx1 = R * x1\n",
    "            tx2 = R * x2\n",
    "            sim_diff = similarity(x1,x2,v_type) - similarity(tx1,tx2,v_type)\n",
    "            \n",
    "            summed_sim_diff += sim_diff\n",
    "        t1 = time.time()\n",
    "        all_sim_diffs.append(summed_sim_diff)\n",
    "        runtimes.append(t1-t0)\n",
    "        ks.append(k)\n",
    "    output = {\"summed_sim_diffs\": all_sim_diffs, \"runtimes\": runtimes, \"ks\":ks, \"numpairs\": numpairs}\n",
    "    return output\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'summed_sim_diffs': [np.float64(0.3719394593318564),\n",
       "  np.float64(0.0),\n",
       "  np.float64(-8.392497208503151e-17)],\n",
       " 'runtimes': [0.0011069774627685547,\n",
       "  0.00046896934509277344,\n",
       "  0.00015592575073242188],\n",
       " 'ks': [1, 2, 3],\n",
       " 'numpairs': 4}"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline(a,SVD,\"image\",4,1,4,1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
