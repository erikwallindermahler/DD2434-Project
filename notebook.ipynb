{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project DD2434\n",
    "## Run instructions\n",
    "Tested in python 3.12.6, in a .venv environment\n",
    "\n",
    "## Datasets\n",
    "### Text document datasets\n",
    "The original paper used 4 datsets from different newsgroups, sci.crypt, sci.med, sci.space and soc.religion.christian, which are available at `URL`\n",
    "\n",
    "We also used `DATASET`\n",
    "\n",
    "### Image datasets\n",
    "\n",
    "\n",
    "The original paper used 13 monochromatic images of still life as the basis for the image datasets, which are unfortunately not available any longer. \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "#from torchvision import datasets, transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['ps.useafm'] = True\n",
    "plt.rcParams['pdf.use14corefonts'] = True\n",
    "#plt.rcParams['text.usetex'] = False\n",
    "\n",
    "# Set the font type for PDF output\n",
    "plt.rcParams['pdf.fonttype'] = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalizecolumns(d):\n",
    "    \"\"\"\n",
    "    Return a matrix where the columns have unit length\n",
    "    \"\"\"\n",
    "    \n",
    "    o = np.zeros(d.shape)\n",
    "    for col in range(d.shape[1]):\n",
    "        total_length = 0\n",
    "        for row in range(d.shape[0]):\n",
    "            total_length += d[(row,col)]**2\n",
    "        \n",
    "        for row in range(d.shape[0]):\n",
    "            o[(row,col)] = d[(row,col)]/np.sqrt(total_length)\n",
    "    return o\n",
    "    \n",
    "    \n",
    "\n",
    "def RP(dataset,k):\n",
    "    \"\"\"\n",
    "    Dataset - d x N, where d is the # of dimensions, N is the # of data points.\n",
    "    Creates appropriate matrix R (k x d), to transform into a lower dimension representation\n",
    "    \"\"\"\n",
    "    d = dataset.shape[0]\n",
    "    return normalizecolumns(np.random.normal(size=(k,d)))\n",
    "\n",
    "\n",
    "def SRP(dataset,k):\n",
    "    d = dataset.shape[0]\n",
    "    o = np.zeros((k,d))\n",
    "    for row in range(k):\n",
    "        for col in range(d):\n",
    "            r = np.random.random()\n",
    "            if r < 1/6:\n",
    "                o[(row,col)] = np.sqrt(3)\n",
    "            elif r > 5/6:\n",
    "                o[(row,col)] = -np.sqrt(3)\n",
    "    return normalizecolumns(o)\n",
    "\n",
    "def SVD(dataset,k):\n",
    "    \"\"\"\n",
    "    Returns d x k matrix, correponding to the k largest eigenvalues's eigenvectors.\n",
    "    Calculated through SVD - more efficient methods exist since most are ignored\n",
    "    \"\"\"\n",
    "    svd_res = np.linalg.svd(dataset)\n",
    "    U = svd_res.U\n",
    "    return U[:,:k].transpose()\n",
    "\n",
    "def DCT(dataset,k):\n",
    "    return(scipy.fftpack.dct(dataset,n = k,type=2,norm='ortho').transpose())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(v):\n",
    "    norm = np.linalg.norm(v)\n",
    "    if norm == 0: \n",
    "       return v\n",
    "    return v / norm\n",
    "\n",
    "def similarity(v1,v2,v_type):\n",
    "    \"\"\"\n",
    "    Returns a measurement of similarity, depending on the v_type. \n",
    "    \"\"\"\n",
    "    nv1 = normalize(v1)\n",
    "    nv2 = normalize(v2)\n",
    "    \n",
    "    if v_type == \"text\":\n",
    "        return np.dot(nv1,nv2)\n",
    "    elif v_type == \"image\":\n",
    "        return np.linalg.norm(nv1 - nv2)\n",
    "    else:\n",
    "        raise ValueError(\"Invalid v_type, should be either 'text', or 'image'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.23536292 -0.3967796  -0.3967796  -0.3967796  -0.3967796  -0.3967796\n",
      "  -0.3967796 ]]\n",
      "[[1. 1. 1. 1. 1. 1. 1.]]\n"
     ]
    }
   ],
   "source": [
    "a = np.matrix([[1,2,3,4],[1,2,3,8],[1,2,3,8],[1,2,3,8],[1,2,3,8],[1,2,3,8],[1,2,3,8]])\n",
    "\n",
    "print(SVD(a,1))\n",
    "\n",
    "print(DCT(a,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Dataset: d x N\n",
    "\n",
    "def pipeline(dataset,method,v_type,numpairs,k_min,k_max,k_step):\n",
    "    \n",
    "    N = dataset.shape[1]\n",
    "    \n",
    "    match method:\n",
    "        case \"RP\":\n",
    "            methodfun = RP\n",
    "        case \"SRP\":\n",
    "            methodfun = SRP\n",
    "        case \"SVD\":\n",
    "            methodfun = SVD\n",
    "        case \"DCT\":\n",
    "            methodfun = DCT\n",
    "        case _:\n",
    "            raise ValueError(\"Invalid method string - choose from RP, SRP, SVD, DCT\")\n",
    "    # Select random pairs from the dataset\n",
    "    pairs = []\n",
    "    for i in range(numpairs):\n",
    "        r1 = np.random.randint(N)\n",
    "        r2 = np.random.randint(N)\n",
    "        \n",
    "        # Don't choose the same point twice\n",
    "        while r2 == r1:\n",
    "            r2 = np.random.randint(N)\n",
    "        pairs.append([dataset[:,r1],dataset[:,r2]])\n",
    "    \n",
    "    output = {}\n",
    "    \n",
    "    all_sim_diffs = []\n",
    "    runtimes      = []\n",
    "    ks            = []\n",
    "    \n",
    "    average_errors = []\n",
    "    error_std     = []\n",
    "    \n",
    "    for k in range(k_min,k_max,k_step):\n",
    "        t0 = time.time()\n",
    "        # Tranformation matrix\n",
    "        R = methodfun(dataset,k)\n",
    "        sim_diff_array = []\n",
    "        for pair in pairs:\n",
    "            x1 = pair[0]\n",
    "            x2 = pair[1]\n",
    "            \n",
    "            tx1 = R * x1\n",
    "            tx2 = R * x2\n",
    "            \n",
    "            sim_diff = similarity(x1,x2,v_type) - similarity(tx1,tx2,v_type)\n",
    "            \n",
    "            sim_diff_array.append(sim_diff)\n",
    "        t1 = time.time()\n",
    "        \n",
    "        all_sim_diffs.append(np.mean(sim_diff_array))\n",
    "        average_errors.append(np.average(sim_diff_array))\n",
    "        error_std.append(np.std(sim_diff_array))\n",
    "        \n",
    "        runtimes.append(t1-t0)\n",
    "        ks.append(k)\n",
    "    output = {\"method\": method,\n",
    "              \"summed_sim_diffs\": all_sim_diffs,\n",
    "              \"runtimes\": runtimes,\n",
    "              \"ks\":ks,\n",
    "              \"numpairs\": numpairs,\n",
    "              \"average_errors\": average_errors,\n",
    "              \"error_stds\": error_std}\n",
    "    return output\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'method': 'DCT',\n",
       " 'summed_sim_diffs': [np.float64(0.04649243241648205),\n",
       "  np.float64(0.04649243241648198),\n",
       "  np.float64(0.04649243241648194)],\n",
       " 'runtimes': [0.0007119178771972656,\n",
       "  0.0004000663757324219,\n",
       "  0.00017118453979492188],\n",
       " 'ks': [1, 2, 3],\n",
       " 'numpairs': 4,\n",
       " 'average_errors': [np.float64(0.04649243241648205),\n",
       "  np.float64(0.04649243241648198),\n",
       "  np.float64(0.04649243241648194)],\n",
       " 'error_stds': [np.float64(0.08052725511280918),\n",
       "  np.float64(0.08052725511280917),\n",
       "  np.float64(0.08052725511280918)]}"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline(a,\"DCT\",\"image\",4,1,4,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_results(iter_of_pipelines):\n",
    "    \n",
    "    plt.figure()\n",
    "    plt.xlabel(\"Number of dimensions in reduced space (k)}\")\n",
    "    plt.ylabel(\"Average error in similarity\")\n",
    "    for result in iter_of_pipelines:\n",
    "        method = result[\"method\"]\n",
    "        summed_sim_diffs = result[\"summed_sim_diffs\"]\n",
    "        av_error = result[\"average_errors\"]\n",
    "        runtimes = result[\"runtimes\"]\n",
    "        ks = result[\"ks\"]\n",
    "        \n",
    "        plt.plot(ks,av_error,\"x\",label=f\"{method}\")\n",
    "    plt.legend()\n",
    "    plt.savefig(f\"figures/average_errors.pdf\")\n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'transforms' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[56], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m#from torchvision import datasets, transforms\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m transform \u001b[38;5;241m=\u001b[39m \u001b[43mtransforms\u001b[49m\u001b[38;5;241m.\u001b[39mToTensor()\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m#fashion_mnist_train = datasets.FashionMNIST(root='./data', train=True, download=True, transform=transform)\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m#fashion_mnist_test = datasets.FashionMNIST(root='./data', train=False, download=True, transform=transform)\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m#print(f\"Training samples: {len(fashion_mnist_train)}, Test samples: {len(fashion_mnist_test)}\")\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Dataset\n",
      "\u001b[0;31mNameError\u001b[0m: name 'transforms' is not defined"
     ]
    }
   ],
   "source": [
    "#from torchvision import datasets, transforms\n",
    "\n",
    "transform = transforms.ToTensor()\n",
    "#fashion_mnist_train = datasets.FashionMNIST(root='./data', train=True, download=True, transform=transform)\n",
    "#fashion_mnist_test = datasets.FashionMNIST(root='./data', train=False, download=True, transform=transform)\n",
    "\n",
    "#print(f\"Training samples: {len(fashion_mnist_train)}, Test samples: {len(fashion_mnist_test)}\")\n",
    "\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import os\n",
    "\n",
    "class TinyImageNetTestDataset(Dataset):\n",
    "    def __init__(self, root, transform=None):\n",
    "        self.root = root\n",
    "        self.transform = transform\n",
    "        self.image_paths = [\n",
    "            os.path.join(root, fname) for fname in os.listdir(root) if fname.endswith(\".JPEG\")\n",
    "        ]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.image_paths[idx]\n",
    "        image = Image.open(img_path).convert(\"RGB\")  # Convert to RGB\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image, img_path  # Return image and its path\n",
    "\n",
    "# Define a transform\n",
    "transform = transforms.Compose([ \n",
    "    transforms.Grayscale(num_output_channels=1), # grayscale \n",
    "    transforms.ToTensor(),          # Convert to Tensor\n",
    "])\n",
    "\n",
    "# Instantiate the dataset\n",
    "test_dataset = TinyImageNetTestDataset(root='./tiny-imagenet-200/test/images', transform=transform)\n",
    "\n",
    "# Access the first sample\n",
    "image, img_path = test_dataset[0]\n",
    "image = np.squeeze(image)\n",
    "print(\"Image size:\", image.shape)\n",
    "print(\"Image path:\", img_path)\n",
    "\n",
    "im_vec = np.reshape(image, (64**2,1))\n",
    "\n",
    "print(im_vec.shape)\n",
    "print(im_vec)\n",
    "plt.imshow(image)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
